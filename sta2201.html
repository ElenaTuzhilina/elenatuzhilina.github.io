<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html">About&nbsp;me</a></div>
<div class="menu-item"><a href="resume.html">Resume</a></div>
<div class="menu-category">Research</div>
<div class="menu-item"><a href="projects.html">Projects</a></div>
<div class="menu-item"><a href="publications.html">Publications</a></div>
<div class="menu-item"><a href="conferences.html">Conferences</a></div>
<div class="menu-item"><a href="software.html">Software</a></div>
<div class="menu-category">Teaching &amp; mentoring</div>
<div class="menu-item"><a href="instructor.html" class="current">Instructor</a></div>
<div class="menu-item"><a href="students.html">Students</a></div>
<div class="menu-category">Blog</div>
<div class="menu-item"><a href="blog/stats-blog.html">Statistics</a></div>
<div class="menu-item"><a href="ds_blog.html">Data&nbsp;science</a></div>
</td>
<td id="layout-content">
<h2><i>STA 2201</i>: Methods of Applied Statistics II</h2>
<p><i>This course provides an in-depth exploration of fundamental statistical techniques, focusing on both unsupervised and supervised methods. 
Key topics include clustering algorithms, dimensionality reduction techniques, and supervised classification models. 
Students will gain an understanding of the mathematics underlying these approaches, enhancing their theoretical knowledge and practical skills.</i></p>
<p><i>A significant component of the course emphasizes hands-on implementation, 
where students will apply these methods to analyze and interpret real-world data. 
By the end of the course, participants will be equipped to design, implement, and critically evaluate statistical models in diverse applications.</i></p>
<h3>Course topics</h3>
<ul>
<li><p>Review: Gaussian MVN, matrix decompositions.</p>
</li>
<li><p>High-dimensional data and curse of dimensionality.</p>
</li>
<li><p>Principal component analysis: three ways to interpret PCA.</p>
</li>
<li><p>More on PCA: functional, kernel and sparse PCA, PCA with missing values, stability of principal components.</p>
</li>
<li><p>Non-linear dimension reduction techniques: t-SNE and UMAP. </p>
</li>
<li><p>Clustering methods: k-means, gaussian mixture models, spectral and hierarchical clustering.</p>
</li>
<li><p>Classification methods: logistic regression, KNN, linear and quadratic discriminant analysis.</p>
</li>
</ul>
<p>We will use R programming language for computations. RStudio is a user-friendly environment for developing, 
running, and documenting R code. R is available for free from CRAN, along with RStudio 
for a nicer user interface. Downloading and installing R and RStudio on your computer is highly recommended for optimal 
performance and flexibility. However, if you prefer, you can use the server version of RStudio.  </p>
<h3>Course content</h3>
<table id="TABLENAME">
<tr class="r1"><td class="c1"></td><td class="c2"> <b>Lecture notes</b> </td><td class="c3"> <b>Practice</b> </td></tr>
<tr class="r2"><td class="c1">Lecture 1  </td><td class="c2"> <a href="courses/sta2201/Lectures/part1_annotated_matrix_decomposition.pdf" target=&ldquo;blank&rdquo;>Matrix decomposition</a> </td><td class="c3"> <a href="courses/sta2201/Practice/practice1_matrix_decomposition.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r3"><td class="c1">Lecture 2  </td><td class="c2"> <a href="courses/sta2201/Lectures/part2_annotated_mvn.pdf" target=&ldquo;blank&rdquo;>Multivariate normal distribution</a>  </td><td class="c3">  <a href="courses/sta2201/Practice/practice2_mvn.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r4"><td class="c1">Lecture 3  </td><td class="c2"> <a href="courses/sta2201/Lectures/part3_annotated_curse_of_dimensionality.pdf" target=&ldquo;blank&rdquo;>Curse of dimensionality</a></td><td class="c3">  <a href="courses/sta2201/Practice/practice3_curse_of_dimensionality.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r5"><td class="c1">Lecture 4  </td><td class="c2"> <a href="courses/sta2201/Lectures/part4_annotated_pca.pdf" target=&ldquo;blank&rdquo;>Principal component analysis</a> </td><td class="c3">  <a href="courses/sta2201/Practice/practice4_pca.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r6"><td class="c1">Lecture 5  </td><td class="c2"> <a href="courses/sta2201/Lectures/part5_annotated_low-rank_matrix_approximation.pdf" target=&ldquo;blank&rdquo;>Low-rank matrix approximation</a>  </td><td class="c3">  <a href="courses/sta2201/Practice/practice5_low_rank_data.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r7"><td class="c1">Lecture 6  </td><td class="c2"> <a href="courses/sta2201/Lectures/part6_annotated_pca_variations.pdf" target=&ldquo;blank&rdquo;>PCA variations</a> </td><td class="c3"> <a href="courses/sta2201/Practice/practice6_pca_variations.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r8"><td class="c1">Lecture 7  </td><td class="c2"> <a href="courses/sta2201/Lectures/part7_annotated_clustering_kmeans.pdf" target=&ldquo;blank&rdquo;>K-means clustering</a>  </td><td class="c3">  <a href="courses/sta2201/Practice/practice7_kmeans.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r9"><td class="c1">Lecture 8  </td><td class="c2"> <a href="courses/sta2201/Lectures/part8_annotated_clustering_gmm.pdf" target=&ldquo;blank&rdquo;>Hierarchical clustering and Gaussian mixture models</a> </td><td class="c3">  <a href="courses/sta2201/Practice/practice8_hierarchical_gmm.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r10"><td class="c1">Lecture 9  </td><td class="c2"> <a href="courses/sta2201/Lectures/part9_annotated_clustering_spectral.pdf" target=&ldquo;blank&rdquo;>Spectral clustering</a> </td><td class="c3">  <a href="courses/sta2201/Practice/practice9_spectral_clustering.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r11"><td class="c1">Lecture 10  </td><td class="c2"> <a href="courses/sta2201/Lectures/part10_annotated_classification_lda.pdf" target=&ldquo;blank&rdquo;>Linear discriminant analysis</a>  </td><td class="c3">  <a href="courses/sta2201/Practice/practice10_classification_lda.html" target=&ldquo;blank&rdquo;>practice</a> </td></tr>
<tr class="r12"><td class="c1">Lecture 11  </td><td class="c2"> <a href="courses/sta2201/Lectures/part11_annotated_classification_lr_knn.pdf" target=&ldquo;blank&rdquo;>Logistic regression and K-nearest neighbors</a> </td><td class="c3"> <a href="courses/sta2201/Practice/practice11_classification_lr_knn.html" target=&ldquo;blank&rdquo;>practice</a>
</td></tr></table>
<div id="footer">
<div id="footer-text">
Page generated 2025-04-18 13:13:16 Eastern Summer Time, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
